import warnings, os
warnings.filterwarnings("ignore")
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score
import xgboost as xgb
import joblib

DATA_PATH = "/content/Churn_Modelling (1).csv"
TARGET_COL = "Exited"
MODEL_OUTPUT = "xgb_bank_churn_model.joblib"
PREDICTIONS_CSV = "bank_churn_predictions_for_powerbi.csv"
RANDOM_STATE = 42

df = pd.read_csv(DATA_PATH)
for c in ["RowNumber", "CustomerId", "Surname"]:
    if c in df.columns:
        df = df.drop(columns=c)
df[TARGET_COL] = df[TARGET_COL].astype(int)

num_feats = [c for c in ["CreditScore", "Age", "Tenure", "Balance", "NumOfProducts", "EstimatedSalary"] if c in df.columns]
cat_feats = [c for c in ["Geography", "Gender", "HasCrCard", "IsActiveMember"] if c in df.columns]
for c in ["HasCrCard", "IsActiveMember"]:
    if c in df.columns and df[c].dtype in [np.int64, np.float64]:
        df[c] = df[c].fillna(0).astype(int).astype(str)
        if c not in cat_feats:
            cat_feats.append(c)
        if c in num_feats:
            num_feats.remove(c)

X = df[num_feats + cat_feats]
y = df[TARGET_COL]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)

numeric_transformer = Pipeline([("imputer", SimpleImputer(strategy="median")), ("scaler", StandardScaler())])
categorical_transformer = Pipeline([("imputer", SimpleImputer(strategy="most_frequent")), ("onehot", OneHotEncoder(handle_unknown="ignore"))])
preprocessor = ColumnTransformer([("num", numeric_transformer, num_feats), ("cat", categorical_transformer, cat_feats)])

xgb_clf = xgb.XGBClassifier(
    objective="binary:logistic",
    eval_metric="auc",
    use_label_encoder=False,
    n_estimators=400,
    learning_rate=0.03,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    min_child_weight=2,
    gamma=0.3,
    scale_pos_weight=1,
    n_jobs=-1,
    random_state=RANDOM_STATE
)

pipe = Pipeline([("preproc", preprocessor), ("model", xgb_clf)])
pipe.fit(X_train, y_train)

y_pred = pipe.predict(X_test)
y_proba = pipe.predict_proba(X_test)[:, 1]

acc = accuracy_score(y_test, y_pred)
auc = roc_auc_score(y_test, y_proba)
print(f"Accuracy: {acc:.4f}")
print(f"ROC-AUC: {auc:.4f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
fig, ax = plt.subplots(figsize=(5, 4))
ax.matshow(cm, cmap=plt.cm.Blues)
for (i, j), val in np.ndenumerate(cm):
    ax.text(j, i, val, ha="center", va="center")
ax.set_xlabel("Predicted")
ax.set_ylabel("Actual")
plt.tight_layout()
plt.show()

fpr, tpr, _ = roc_curve(y_test, y_proba)
plt.plot(fpr, tpr, label=f"AUC = {auc:.3f}")
plt.plot([0,1],[0,1],"--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()

ohe = pipe.named_steps["preproc"].named_transformers_["cat"].named_steps["onehot"]
ohe_feature_names = list(ohe.get_feature_names_out(cat_feats))
feature_names = num_feats + ohe_feature_names
importances = pipe.named_steps["model"].feature_importances_
fi = pd.DataFrame({"feature": feature_names, "importance": importances}).sort_values("importance", ascending=False).head(20)
plt.barh(fi["feature"][::-1], fi["importance"][::-1])
plt.xlabel("Importance")
plt.title("Top 20 Feature Importances")
plt.tight_layout()
plt.show()

joblib.dump(pipe, MODEL_OUTPUT)
export_df = X_test.copy()
export_df["actual_exited"] = y_test.values
export_df["predicted_exited"] = y_pred
export_df["predicted_proba"] = y_proba
export_df.to_csv(PREDICTIONS_CSV, index=False)

print("\nModel saved as:", MODEL_OUTPUT)
print("Predictions exported to:", PREDICTIONS_CSV)
